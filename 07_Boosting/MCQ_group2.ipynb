{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Second MCQ\n",
    "\n",
    "Group 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. How can you increase the regularization within a decision tree?\n",
    "- A. By switching between gini impurity and entropy\n",
    "- B. By increasing the minimum number of samples in a leaf\n",
    "- C. By decreasing the minimum number of samples in a leaf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. How can you increase the regularization within a decision tree?\n",
    "- A. By switching between gini impurity and entropy\n",
    "- B. **By increasing the minimum number of samples in a leaf**\n",
    "- C. By decreasing the minimum number of samples in a leaf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. For a given task you have trained 5 models. Given the following accuracy score on the training and validation sets, which one would you choose?\n",
    "- A. Training = 0.71; Validation = 0.70\n",
    "- B. Training = 0.86; Validation = 0.85\n",
    "- C. Training = 0.75; Validation = 0.67\n",
    "- D. Training = 0.99; Validation = 0.85\n",
    "- E. Training = 0.97; Validation = 0.81\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. For a given task you have trained 5 models. Given the following accuracy score on the training and validation sets, which one would you choose?\n",
    "- A. Training = 0.71; Validation = 0.70\n",
    "- **B. Training = 0.86; Validation = 0.85**\n",
    "- C. Training = 0.75; Validation = 0.67\n",
    "- D. Training = 0.99; Validation = 0.85\n",
    "- E. Training = 0.97; Validation = 0.81\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. What are the uses of the train and the validation sets?\n",
    "- A. The train set is used to train the model, the validation set to evaluate the model\n",
    "- B. The train set is used to optimize hyperparameters of the model, the validation set to evaluate the model\n",
    "- C. The train set is used to train the model, the validation set to optimize the hyperparameters of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. What are the uses of the train and the validation sets?\n",
    "- A. The train set is used to train the model, the validation set to evaluate the model\n",
    "- B. The train set is used to optimize hyperparameters of the model, the validation set to evaluate the model\n",
    "- **C. The train set is used to train the model, the validation set to optimize the hyperparameters of the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Why is it recommended to prepare the data after the split train test split?\n",
    "- A. Because it is easier to prepare the data after the split\n",
    "- B. Because during the missing data imputation, information can leak from the test set to the train set\n",
    "- C. Because during the missing data imputation, information can leak from the train set to the test set\n",
    "- D. Because it is impossible to apply one hot encoding correctly before the split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Why is it recommended to prepare the data after the split train test split?\n",
    "- A. Because it is easier to prepare the data after the split\n",
    "- B. Because during the missing data imputation, information can leak from the test set to the train set\n",
    "- **C. Because during the missing data imputation, information can leak from the train set to the test set**\n",
    "- D. Because it is impossible to apply one hot encoding correctly before the split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5. When is stratification highly recommended to ensure good performances?\n",
    "- A. Stratification is always highly recommended, no matter the data and the task\n",
    "- B. For a classification task with perfectly balanced classes\n",
    "- C. For a classification task with imbalanced classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5. When is stratification highly recommended to ensure good performances?\n",
    "- A. Stratification is always highly recommended, no matter the data and the task\n",
    "- B. For a classification task with perfectly balanced classes\n",
    "- **C. For a classification task with imbalanced classes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6. A data scientist is evaluating different binary classification models. A false negative result is 5 times more expensive (from a business perspective) than a false positive result.\n",
    "The models should be evaluated based on the following criteria:\n",
    "1. Must have a recall of at least 80%\n",
    "2. Must have a an accuracy of at least 85%\n",
    "3. Must minimize business costs\n",
    "\n",
    "After creating each binary classification model, the data scientist generates the corresponding confusion matrix. Which confusion matrix represents the model that satisfies the requirements?\n",
    "- A. TN = 91, FP = 9, FN = 22, TP = 78 \n",
    "- B. TN = 99, FP = 1, FN = 21, TP = 79\n",
    "- C. TN = 96, FP = 4, FN = 10, TP = 90\n",
    "- D. TN = 98, FP = 2, FN = 18, TP = 82\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A. Recall = TP/(TP+FN) = 78/(78+22) = 0.78\n",
    "Accuracy = 84.5\n",
    "\n",
    "B.Recall =  0.79\n",
    "Accuracy = 0.89\n",
    "\n",
    "C.Recall = 0.9\n",
    "Accuracy = 93\n",
    "\n",
    "D.Recall = 0.82\n",
    "Accuracy = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6. A data scientist is evaluating different binary classification models. A false negative result is 5 times more expensive (from a business perspective) than a false positive result.\n",
    "The models should be evaluated based on the following criteria:\n",
    "1. Must have a recall of at least 80%\n",
    "2. Must have a an accuracy of at least 85%\n",
    "3. Must minimize business costs\n",
    "\n",
    "After creating each binary classification model, the data scientist generates the corresponding confusion matrix. Which confusion matrix represents the model that satisfies the requirements?\n",
    "- A. TN = 91, FP = 9, FN = 22, TP = 78 \n",
    "- B. TN = 99, FP = 1, FN = 21, TP = 79\n",
    "- **C. TN = 96, FP = 4, FN = 10, TP = 90**\n",
    "- D. TN = 98, FP = 2, FN = 18, TP = 82\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 7. Given the following confusion matrix, what is the Recall score of the positive class?\n",
    "\n",
    "\n",
    "| | Negative Class | Positive Class |\n",
    "|:-:|:-:|:-:|\n",
    "|Predicted Negative | 49 | 2 |\n",
    "| Predicted Positive | 8 | 41 |\n",
    "\n",
    "- A. 41/43\n",
    "- B. 41/49\n",
    "- C. 49/51\n",
    "- D. 49/57\n",
    "- E. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reminder:\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 7. Given the following confusion matrix, what is the Recall score of the positive class?\n",
    "\n",
    "\n",
    "| | Negative Class | Positive Class |\n",
    "|:-:|:-:|:-:|\n",
    "|Predicted Negative | 49 | 2 |\n",
    "| Predicted Positive | 8 | 41 |\n",
    "\n",
    "- **A. 41/43**\n",
    "- B. 41/49\n",
    "- C. 49/51\n",
    "- D. 49/57\n",
    "- E. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 8. Given the following confusion matrix, what is the Accuracy score?\n",
    "\n",
    "| | Negative Class | Positive Class |\n",
    "|:-:|:-:|:-:|\n",
    "|Predicted Negative | 49 | 2 |\n",
    "| Predicted Positive | 8 | 41 |\n",
    "\n",
    "- A. 82%\n",
    "- B. 98%\n",
    "- C. 90%\n",
    "- D. 95%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reminder:\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 8. Given the following confusion matrix, what is the Accuracy score?\n",
    "\n",
    "| | Negative Class | Positive Class |\n",
    "|:-:|:-:|:-:|\n",
    "|Predicted Negative | 49 | 2 |\n",
    "| Predicted Positive | 8 | 41 |\n",
    "\n",
    "- A. 82%\n",
    "- B. 98%\n",
    "- **C. 90%**\n",
    "- D. 95%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 9. Given the following confusion matrix, what is the ROC area under curve score?\n",
    "\n",
    "| | Negative Class | Positive Class |\n",
    "|:-:|:-:|:-:|\n",
    "|Predicted Negative | 49 | 1 |\n",
    "| Predicted Positive | 1 | 49 |\n",
    "\n",
    "- A. 0.5\n",
    "- B. 0.98\n",
    "- C. 0.90\n",
    "- D. 0.99\n",
    "- E. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 9. Given the following confusion matrix, what is the ROC area under curve score?\n",
    "\n",
    "| | Negative Class | Positive Class |\n",
    "|:-:|:-:|:-:|\n",
    "|Predicted Negative | 49 | 1 |\n",
    "| Predicted Positive | 1 | 49 |\n",
    "\n",
    "- A. 0.5\n",
    "- B. 0.98\n",
    "- C. 0.90\n",
    "- D. 0.99\n",
    "- **E. Not enough information are provided**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 10. What is the ROC AUC score of a random binary classification model?\n",
    "- A. 0\n",
    "- B. 0.5\n",
    "- C. 0.25\n",
    "- D. 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 10. What is the ROC AUC score of a random binary classification model?\n",
    "- A. 0\n",
    "- **B. 0.5**\n",
    "- C. 0.25\n",
    "- D. 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 11. Which, in the following list, are common regression metrics?\n",
    "- A. Min Squared Error\n",
    "- B. Mean Absolute Error\n",
    "- C. Min Absolute Error\n",
    "- D. Binary Cross Entropy\n",
    "- E. R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 11. Which, in the following list, are common regression metrics?\n",
    "- A. Min Squared Error\n",
    "- **B. Mean Absolute Error**\n",
    "- C. Min Absolute Error\n",
    "- D. Binary Cross Entropy\n",
    "- **E. R2 score**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 12. Let’s consider the following accuracy results for a classification model\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:-:|:-:|\n",
    "|Train | 0.75 |\n",
    "| Validation | 0.74 |\n",
    "\n",
    "How would you consider this model?\n",
    "- A. This model has high bias\n",
    "- B. This model has high variance\n",
    "- C. This model seems “just right”\n",
    "- D. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 12. Let’s consider the following accuracy results for a classification model\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:-:|:-:|\n",
    "|Train | 0.75 |\n",
    "| Validation | 0.74 |\n",
    "\n",
    "How would you consider this model?\n",
    "- A. This model has high bias\n",
    "- B. This model has high variance\n",
    "- C. This model seems “just right”\n",
    "- **D. Not enough information are provided**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 13. Let’s consider the following accuracy results for a spam classification model\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:-:|:-:|\n",
    "|Train | 0.98 |\n",
    "| Validation | 0.85 |\n",
    "\n",
    "How would you consider this model?\n",
    "- A. This model has high bias\n",
    "- B. This model has high variance\n",
    "- C. This model seems “just right”\n",
    "- D. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 13. Let’s consider the following accuracy results for a spam classification model\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:-:|:-:|\n",
    "|Train | 0.98 |\n",
    "| Validation | 0.85 |\n",
    "\n",
    "How would you consider this model?\n",
    "- A. This model has high bias\n",
    "- **B. This model has high variance**\n",
    "- C. This model seems “just right”\n",
    "- D. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 14. Let’s consider the following accuracy results for a handwritten digit classification model\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:-:|:-:|\n",
    "|Train | 99.5% |\n",
    "| Validation | 99.4 % |\n",
    "\n",
    "How would you consider this model?\n",
    "- A. This model has high bias\n",
    "- B. This model has high variance\n",
    "- C. This model seems “just right”\n",
    "- D. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 14. Let’s consider the following accuracy results for a handwritten digit classification model\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:-:|:-:|\n",
    "|Train | 99.5% |\n",
    "| Validation | 99.4 % |\n",
    "\n",
    "How would you consider this model?\n",
    "- A. This model has high bias\n",
    "- B. This model has high variance\n",
    "- **C. This model seems “just right”**\n",
    "- D. Not enough information are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 15. When having an overfitting model, what can we try to improve the performances?\n",
    "- A. Reduce regularization (if any)\n",
    "- B. Add regularization\n",
    "- C. Add samples\n",
    "- D. Add features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 15. When having an overfitting model, what can we try to improve the performances?\n",
    "- A. Reduce regularization (if any)\n",
    "- **B. Add regularization**\n",
    "- **C. Add samples**\n",
    "- D. Add features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 16. What can we say about the LASSO Regression?\n",
    "- A. It is a L1 penalized regression\n",
    "- B. It is a L2 penalized regression\n",
    "- C. With large regularization, model parameters will tend to 1\n",
    "- D. With large regularization, model parameters will tend to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 16. What can we say about the LASSO Regression?\n",
    "- **A. It is a L1 penalized regression**\n",
    "- B. It is a L2 penalized regression\n",
    "- C. With large regularization, model parameters will tend to 1\n",
    "- **D. With large regularization, model parameters will tend to 0**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 17. Decision trees are natively non linear models?\n",
    "- A. False\n",
    "- B. True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 17. Decision trees are natively non linear models?\n",
    "- A. False\n",
    "- **B. True**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 18. Below are 8 labels of a dataset.\n",
    "[0,0,0,1,1,1,1,1]\n",
    "What is the entropy of this dataset? \n",
    "- A. -$\\frac{5}{8}$log($\\frac{5}{8}$)-$\\frac{3}{8}$log($\\frac{3}{8}$)\n",
    "- B. -$\\frac{5}{8}$log($\\frac{5}{8}$)+$\\frac{3}{8}$log($\\frac{3}{8}$)\n",
    "- C. $\\frac{5}{8}$log($\\frac{5}{8}$)-$\\frac{3}{8}$log($\\frac{3}{8}$)\n",
    "- D. $\\frac{5}{8}$log($\\frac{5}{8}$)+$\\frac{3}{8}$log($\\frac{3}{8}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 18. Below are 8 labels of a dataset.\n",
    "[0,0,0,1,1,1,1,1]\n",
    "What is the entropy of this dataset? \n",
    "- **A. -$\\frac{5}{8}$log($\\frac{5}{8}$)-$\\frac{3}{8}$log($\\frac{3}{8}$)**\n",
    "- B. -$\\frac{5}{8}$log($\\frac{5}{8}$)+$\\frac{3}{8}$log($\\frac{3}{8}$)\n",
    "- C. $\\frac{5}{8}$log($\\frac{5}{8}$)-$\\frac{3}{8}$log($\\frac{3}{8}$)\n",
    "- D. $\\frac{5}{8}$log($\\frac{5}{8}$)+$\\frac{3}{8}$log($\\frac{3}{8}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 19. A grid search with the following arguments is performed, with a decision tree classifier model: \n",
    "- max_depth = [2, 3, 5]\n",
    "- criterion = [‘gini’, ‘entropy’]\n",
    "- min_samples_leaf = [5, 10]\n",
    "- Cross validation folds = 5\n",
    "\n",
    "How many models are fitted in this grid search?\n",
    "- A. 12\n",
    "- B. 35\n",
    "- C. 60\n",
    "- D. 18\n",
    "- E. 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 19. A grid search with the following arguments is performed, with a decision tree classifier model: \n",
    "- max_depth = [2, 3, 5]\n",
    "- criterion = [‘gini’, ‘entropy’]\n",
    "- min_samples_leaf = [5, 10]\n",
    "- Cross validation folds = 5\n",
    "\n",
    "How many models are fitted in this grid search?\n",
    "- A. 12\n",
    "- B. 35\n",
    "- **C. 60**\n",
    "- D. 18\n",
    "- E. 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 20. If you have two classes in a dataset, having a gini impurity of 0.5 means the dataset is:\n",
    "- A. Totally pure: there is only one class\n",
    "- B. Completely balanced: both classes are equally represented\n",
    "- C. Not pure: both classes are represented, in an unpredictable balance\n",
    "- D. Impossible to say\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 20. If you have two classes in a dataset, having a gini impurity of 0.5 means the dataset is:\n",
    "- A. Totally pure: there is only one class\n",
    "- **B. Completely balanced: both classes are equally represented**\n",
    "- C. Not pure: both classes are represented, in an unpredictable balance\n",
    "- D. Impossible to say\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
