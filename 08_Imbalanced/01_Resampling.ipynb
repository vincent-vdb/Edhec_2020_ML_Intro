{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# I. Imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In many applications datasets might be **imbalanced**. Meaning, the label classes are not equally represented.\n",
    "\n",
    "Those imbalanced datasets need a special treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.1. Reminder: Imbalanced data and the accuracy paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's work on a real life example: credit card fraud detection. We will work on [this dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "\n",
    "This dataset is made of 33 features, anonymized for confidentiality (except the `Time` and `Amount` features).\n",
    "\n",
    "This dataset is **higly imbalanced**:\n",
    "- 28432 regular transactions\n",
    "- 49 fraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "      <td>28481.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>95208.813455</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>-0.004435</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>88.023627</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47462.019286</td>\n",
       "      <td>1.923268</td>\n",
       "      <td>1.629236</td>\n",
       "      <td>1.478621</td>\n",
       "      <td>1.430630</td>\n",
       "      <td>1.338637</td>\n",
       "      <td>1.318965</td>\n",
       "      <td>1.172529</td>\n",
       "      <td>1.156180</td>\n",
       "      <td>1.105621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706742</td>\n",
       "      <td>0.726664</td>\n",
       "      <td>0.603691</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.521487</td>\n",
       "      <td>0.481063</td>\n",
       "      <td>0.399141</td>\n",
       "      <td>0.327958</td>\n",
       "      <td>231.415417</td>\n",
       "      <td>0.041443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>-36.510583</td>\n",
       "      <td>-47.429676</td>\n",
       "      <td>-25.188773</td>\n",
       "      <td>-5.071241</td>\n",
       "      <td>-31.356750</td>\n",
       "      <td>-20.054615</td>\n",
       "      <td>-28.215112</td>\n",
       "      <td>-41.484823</td>\n",
       "      <td>-9.481456</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.262054</td>\n",
       "      <td>-8.593642</td>\n",
       "      <td>-19.935025</td>\n",
       "      <td>-2.822684</td>\n",
       "      <td>-5.785255</td>\n",
       "      <td>-1.658162</td>\n",
       "      <td>-8.878665</td>\n",
       "      <td>-8.424041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54428.000000</td>\n",
       "      <td>-0.907909</td>\n",
       "      <td>-0.606632</td>\n",
       "      <td>-0.898424</td>\n",
       "      <td>-0.850314</td>\n",
       "      <td>-0.690137</td>\n",
       "      <td>-0.768533</td>\n",
       "      <td>-0.548264</td>\n",
       "      <td>-0.211192</td>\n",
       "      <td>-0.643115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228652</td>\n",
       "      <td>-0.545012</td>\n",
       "      <td>-0.160655</td>\n",
       "      <td>-0.363423</td>\n",
       "      <td>-0.316361</td>\n",
       "      <td>-0.321025</td>\n",
       "      <td>-0.070258</td>\n",
       "      <td>-0.052049</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>85310.000000</td>\n",
       "      <td>0.033025</td>\n",
       "      <td>0.069165</td>\n",
       "      <td>0.165844</td>\n",
       "      <td>-0.013895</td>\n",
       "      <td>-0.047706</td>\n",
       "      <td>-0.275393</td>\n",
       "      <td>0.044389</td>\n",
       "      <td>0.020769</td>\n",
       "      <td>-0.055640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030396</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>-0.010354</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>0.017748</td>\n",
       "      <td>-0.050598</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.011636</td>\n",
       "      <td>21.990000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139497.000000</td>\n",
       "      <td>1.317317</td>\n",
       "      <td>0.809194</td>\n",
       "      <td>1.010925</td>\n",
       "      <td>0.749306</td>\n",
       "      <td>0.616385</td>\n",
       "      <td>0.409577</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.328586</td>\n",
       "      <td>0.599622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189373</td>\n",
       "      <td>0.523466</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>0.438738</td>\n",
       "      <td>0.350675</td>\n",
       "      <td>0.241081</td>\n",
       "      <td>0.092322</td>\n",
       "      <td>0.079345</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172769.000000</td>\n",
       "      <td>2.446505</td>\n",
       "      <td>15.536133</td>\n",
       "      <td>3.934537</td>\n",
       "      <td>11.844777</td>\n",
       "      <td>29.016124</td>\n",
       "      <td>20.379524</td>\n",
       "      <td>30.897666</td>\n",
       "      <td>15.374630</td>\n",
       "      <td>9.272376</td>\n",
       "      <td>...</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>5.805795</td>\n",
       "      <td>20.803344</td>\n",
       "      <td>3.990646</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>10.507884</td>\n",
       "      <td>22.620072</td>\n",
       "      <td>7583.320000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count   28481.000000  28481.000000  28481.000000  28481.000000  28481.000000   \n",
       "mean    95208.813455      0.012726      0.000476     -0.004435      0.012655   \n",
       "std     47462.019286      1.923268      1.629236      1.478621      1.430630   \n",
       "min        17.000000    -36.510583    -47.429676    -25.188773     -5.071241   \n",
       "25%     54428.000000     -0.907909     -0.606632     -0.898424     -0.850314   \n",
       "50%     85310.000000      0.033025      0.069165      0.165844     -0.013895   \n",
       "75%    139497.000000      1.317317      0.809194      1.010925      0.749306   \n",
       "max    172769.000000      2.446505     15.536133      3.934537     11.844777   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  28481.000000  28481.000000  28481.000000  28481.000000  28481.000000   \n",
       "mean       0.007934     -0.005479      0.003352     -0.005039      0.000943   \n",
       "std        1.338637      1.318965      1.172529      1.156180      1.105621   \n",
       "min      -31.356750    -20.054615    -28.215112    -41.484823     -9.481456   \n",
       "25%       -0.690137     -0.768533     -0.548264     -0.211192     -0.643115   \n",
       "50%       -0.047706     -0.275393      0.044389      0.020769     -0.055640   \n",
       "75%        0.616385      0.409577      0.573937      0.328586      0.599622   \n",
       "max       29.016124     20.379524     30.897666     15.374630      9.272376   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  28481.000000  28481.000000  28481.000000  28481.000000   \n",
       "mean   ...      0.001718     -0.002135      0.004524     -0.005816   \n",
       "std    ...      0.706742      0.726664      0.603691      0.607972   \n",
       "min    ...    -20.262054     -8.593642    -19.935025     -2.822684   \n",
       "25%    ...     -0.228652     -0.545012     -0.160655     -0.363423   \n",
       "50%    ...     -0.030396      0.004597     -0.010354      0.036670   \n",
       "75%    ...      0.189373      0.523466      0.148269      0.438738   \n",
       "max    ...     22.614889      5.805795     20.803344      3.990646   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  28481.000000  28481.000000  28481.000000  28481.000000  28481.000000   \n",
       "mean      -0.000319      0.003983     -0.000625     -0.000613     88.023627   \n",
       "std        0.521487      0.481063      0.399141      0.327958    231.415417   \n",
       "min       -5.785255     -1.658162     -8.878665     -8.424041      0.000000   \n",
       "25%       -0.316361     -0.321025     -0.070258     -0.052049      5.940000   \n",
       "50%        0.017748     -0.050598      0.001450      0.011636     21.990000   \n",
       "75%        0.350675      0.241081      0.092322      0.079345     77.700000   \n",
       "max        7.519589      3.517346     10.507884     22.620072   7583.320000   \n",
       "\n",
       "              Class  \n",
       "count  28481.000000  \n",
       "mean       0.001720  \n",
       "std        0.041443  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fraud.csv')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28432\n",
       "1       49\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the class balance\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Any model that **always predicts regular transactions** would have an **accuracy greater than 99%**.\n",
    "\n",
    "Then accuracy is **not the right metric**. What could we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.2. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's train a simple model on our data: a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Define X and y\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "# Predict on test dataset\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.3. Classification evaluation with imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's compute the confusion matrix at first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5686,    1],\n",
       "       [   7,    3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our model provides the following results on the dataset:\n",
    "\n",
    "| | Regular | Fraud | \n",
    "|:------:|:------:|:------:|\n",
    "| Predicted Regular | 5686 | 7 |\n",
    "| Predicted Fraud | 1 | 3 |\n",
    "\n",
    "Let's compute the accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985957521502545\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The accuracy is hitting the roof, as expected. But is it really that good? Let's look at the other metrics:\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.75\n",
      "Recall: 0.3\n",
      "F1-score: 0.4285714285714285\n"
     ]
    }
   ],
   "source": [
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Those metrics seem much more realistic about the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, have a look at the ROC AUC metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9296113944082997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Get the probas\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
    "# Compute the ROC AUC\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba))\n",
    "# Display the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> ROC AUC is also a better choice than the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.4. Limits with imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At the end of the day, the problem remains:\n",
    "- the model may not have enough underrepresented class data to understand it\n",
    "- the model may have too much overrepresented class data to notice the other class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What could we do to help the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are two main possibilities:\n",
    "- Undersampling\n",
    "- Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# II. Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1. Principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first possible approach is to undersample the overrepresented class: \n",
    "- we keep **all the sample from underrepresented class**\n",
    "- we keep only **a subsample of the overrepresented class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As a reminder, this dataset has the following class balance:\n",
    "- 28432 regular transactions\n",
    "- 49 fraudulent transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A typical Random Undersampling would be to increase the balanced by **dropping regular samples**, to have a 1/10 ratio for example:\n",
    "- 441 regular transactions\n",
    "- 49 fraudulent transactions\n",
    "\n",
    "We would then have $\\frac{49}{490} = 10 %$ of fraudulent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> The drawback of this extreme method is that we **lose most of our data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.2. Implementation with `imblearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This method can be applied using the **`imbalanced-learn`** library. If needed, you can install it with :\n",
    "```bash\n",
    "conda install -c conda-forge imbalanced-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, we will use the following class:\n",
    "\n",
    "```python\n",
    "class imblearn.under_sampling.RandomUnderSampler(sampling_strategy='auto', return_indices=False, random_state=None, replacement=False, ratio=None)\n",
    "```\n",
    "\n",
    "More details about this [here on the Imbalanced Learn website](https://imbalanced-learn.readthedocs.io/en/stable/under_sampling.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    390\n",
       "1     39\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Instantiate the object with a 10% strategy\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1)\n",
    "# Undersample our train dataset\n",
    "X_rus, y_rus = rus.fit_sample(X_train, y_train)\n",
    "# Check the balance\n",
    "y_rus.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have now a 1/10 ratio between the classes. Let's check if this improves our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.09195402298850575\n",
      "Recall: 0.8\n",
      "F1-score: 0.16494845360824742\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_rus, y_rus)\n",
    "# Predict on test dataset\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The previous results were:\n",
    "- Precision: 0.75\n",
    "- Recall: 0.3\n",
    "- F1-score: 0.4285714285714285\n",
    "\n",
    "It did improve recall, but other metrics are not better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## III. Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## III.1. Random oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the exact opposite approach of random undersampling: instead of removing some overrepresented class samples, we would **duplicate underrepresented class samples** to rebalance the dataset.\n",
    "\n",
    "> Though intuitive, this method is not much efficient: in our case would duplicate each fraud about 500 times to reach balance..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.2. SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another, smarter way of oversampling is the so called *Synthetic Minority Oversampling TEchnique* (SMOTE). \n",
    "\n",
    "instead of duplicates, we would **create new samples** using a **k-NN method** on original data. Let's detail the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Based on the k nearest neighboors of the fraudulent transactions, \n",
    "\n",
    "The first step is to pick randomly a fraudulent sample $x_i$.\n",
    "\n",
    "Then, thanks to k-NN, pick randomly $x_{zi}$, one of the fraudulent k nearest neighboors of $x_i$.\n",
    "\n",
    "You end up having two, close, fradulent transactions. And you will compute a new, synthetic, fraudulent transaction $x_{new}$:\n",
    "$$\n",
    "x_{new} = x_i + \\lambda \\times (x_{zi} - x_i)\n",
    "$$\n",
    "\n",
    "Where $\\lambda$ is a random value between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A visual representation (from the [imblearn documentation](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#mathematical-formulation)) is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1S7iiSzQxlajEPPRX_rwgf-TKeeT4uGmt\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.3. Implementation with `imblearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "SMOTE can also be computed using the `imbalanced-learn` library, with the following signature:\n",
    "\n",
    "```python\n",
    "class imblearn.over_sampling.SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5, m_neighbors='deprecated', out_step='deprecated', kind='deprecated', svm_estimator='deprecated', n_jobs=1, ratio=None)\n",
    "```\n",
    "\n",
    "With `k_neighbors` the hyperparameter of the number of neighbors in the k-NN.\n",
    "\n",
    "More [on the Imbalanced Learn website](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#a-practical-guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's apply the method to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22745\n",
       "1     2274\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Instantiate the object with a 10% strategy\n",
    "smote = SMOTE(sampling_strategy=0.1)\n",
    "# SMOTE the train dataset\n",
    "X_smote, y_smote = smote.fit_sample(X_train, y_train)\n",
    "# Check the balance\n",
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This indeed increased the number of fradulent transactions. Let's fit and evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.24242424242424243\n",
      "Recall: 0.8\n",
      "F1-score: 0.372093023255814\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_smote, y_smote)\n",
    "# Predict on test dataset\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The previous results were:\n",
    "- Precision: 0.75\n",
    "- Recall: 0.3\n",
    "- F1-score: 0.4285714285714285\n",
    "\n",
    "It did improve recall and slightly the F1-score, but precision is still lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> For a robust evaluation and comparison, hyperparameter optimization should be performed"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
