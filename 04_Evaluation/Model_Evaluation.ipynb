{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation and metrics\n",
    "- train test split\n",
    "- metrics for classification\n",
    "- metrics for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Evaluation ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1bjrsYhVwc2HYB1FFJKUK6AoyQ27ujJRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# I. Training Set & Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is particularly important to separate the data that you use for **training** your model, and the data that you use for **testing** your model.\n",
    "\n",
    "Otherwise it is too easy! üôà\n",
    "\n",
    "It would be like a student practicing on sample questions for his/her exams, and being tested on the exact same question. \n",
    "\n",
    "You need to be tested on **new questions** in order to make sure you **learnt correctly**.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1x4j8bjbFbkSUKKsRPcPAGeJs8JF1OI9g\" width=\"350\">\n",
    "</p>\n",
    "\n",
    "For one given labeled dataset, we often split it in a **training set** and a **test set** with the associated repartition: **80%** - **20%**, but you can choose to split your dataset as you want.\n",
    "\n",
    "> üî¶ **Hint**: This convention allows to retrieve sufficient data to learn from it, and a small subset in order to understand the performance.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1I0Dn2d0RUM1BrOGG40VKwJHfKE-Lh6VE\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "To recap, we have:\n",
    "\n",
    "-  a **Training set**: A set of observations used for **learning**. It **fits the parameters (or weights) of the model**.\n",
    "   \n",
    "    Commonly noted `X_train` (for the features) and `y_train` for the corresponding targets.\n",
    "\n",
    "\n",
    "- a **Test set**: A set of observations (unseen during training) used only to **assess the performance** of the model.\n",
    "\n",
    "    Commonly noted `X_test` (for the features) and `y_test` for the corresponding targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn provides a function to split your data into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# II. Evaluation for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.1. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's consider a classification model that predicts if a mushroom is eatable or not (0 = Not Eatable, 1 = Eatable).\n",
    "\n",
    "We have seen before, that we could evaluate our classification model by computing the **accuracy**: it corresponds to the number of correct predictions over the total number of predictions.\n",
    "\n",
    "In other words, it's the **percentage of correct predictions** of the model (on the test set).\n",
    "\n",
    "Accuracy is a **global** metric. It is always useful to evaluate the accuracy but sometimes it can be insufficient to evaluate properly your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.2. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let's consider that we obtain these results by testing the model on 200 mushrooms:\n",
    "\n",
    "| üçÑ  | **Is eatable** üòã | **Is not eatable** ‚ò†Ô∏è | \n",
    "|------|------|------|\n",
    "| **Predicted eatable** üëç | 100 | 6¬†|\n",
    "| **Predicted not eatable** üëé | 0 | 94 |\n",
    "\n",
    "We call:\n",
    "* True Positive (TP): the number of predicted positive that are indeed positive - here 100\n",
    "* True Negative (TN): the number of predicted negative that are indeed negative - here 94\n",
    "* False Positive (FP): the number of predicted positive that are in reality negative - here 6\n",
    "* False Negative (FN): the number of predicted negative that are in reality positive - here 0\n",
    "\n",
    "Accuracy as we know it can be defined as:\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FN + FP}$$\n",
    "\n",
    "In our case, $Accuracy = \\frac{100 + 94}{100 + 94 + 0 + 7} = 0.97$ \n",
    "\n",
    "Our model has an accuracy of 97%. Not that bad right?.. \n",
    "\n",
    "But wait.\n",
    "\n",
    "What if we predict to someone that a mushroom is eatable when it's not?! ‚ò†Ô∏è\n",
    "\n",
    "This can cause severe damage, that's why, instead of computing only global accuracy, we can also compute other scores to get a better understanding of the performance of our model.\n",
    "\n",
    "In addition, we can compute new scores per class: \n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1LM2d2k6lPt8g3skTW3MTOErXwORhndYB\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "- **Precision**: How many selected items are relevant?\n",
    "\n",
    "Here, how many mushrooms classified as eatable are indeed eatable? It's 100/106=0.94 (94%) for eatable mushrooms\n",
    "\n",
    "If the goal is to eat the mushrooms afterwards... we might want to improve our model because there is a 6% risk that you get a non-eatable mushroom (classified as eatable)\n",
    "\n",
    "- **Recall**: How many relevant items are selected?\n",
    "\n",
    "Here, how many mushrooms truly eatable are classified as such? It's 100% for eatable mushrooms.\n",
    "\n",
    "It's the ability of our model capacity to classify all eatable mushrooms as such.\n",
    "\n",
    "More precisely, we can write:\n",
    "\n",
    "$${Precision = \\frac{TP}{TP + FP}}$$\n",
    "\n",
    "$${Recall = \\frac{TP}{P} = \\frac{TP}{TP + FN}}$$\n",
    "\n",
    "Finally we can define **F1_score**, which is a measure that combines both Precision metric and Recall metrics:\n",
    "\n",
    "$${F1\\_score = \\frac{2 * (Precision * Recall)}{Precision + Recall}}$$\n",
    "\n",
    "Here, ${F1\\_score = \\frac{2 * (1 * 0.94)}{1 + 0.94} = 0.969\\%}$\n",
    "\n",
    "**F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0**\n",
    "\n",
    "Note that we can define Precision and Recall per class (the same way we just defined them for the class `eatable`.\n",
    "\n",
    "In particular, the Precision for the negative class (here `non-eatable`) is called **Specificity**:\n",
    "\n",
    "$$Specificity = \\frac{TN}{N} = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "> üìö **Resources**: More information about Precision and Recall: https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.3. ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most of the time, a classifier returns a probability (that the input belongs to the corresponding class), and we consider the highest probability as the predicted class.\n",
    "\n",
    "> üî¶ **Hint**: In scikit-learn instead of predicting the class label (with `model.predict(X)`),\n",
    "we can do:\n",
    ">\n",
    "> `y_pred_proba = model.predict_proba(X)`\n",
    "\n",
    "For each value of the threshold, we can compute the **Recall** and the **Specificity**. \n",
    "\n",
    "Then we can plot the curve ROC with Recall in y-axis and 1-Specificity in x-axis:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1II0OImj0Yx6fyDnSNSUH47mxdIAHo7Hq\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "> üìö **Books**: Cool visualization of the ROC curve and impact of data distribution/threshold: http://www.navan.name/roc/\n",
    "\n",
    "**The Area Under the Curve ROC (AUC ROC) indicates how well the probabilities from the positive classes are separated from the negative classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üî¶ **Hint**: For understanding the trade-off of the threshold chosen, consider an airport security. Since passengers can be potential threats to safety, scanners may be set to trigger alarms on low-risk items like belt buckles and keys (**low specificity**) in order to increase the probability of identifying dangerous objects and minimize the risk of missing objects that do pose a threat (**high sensitivity**). \n",
    "\n",
    "\n",
    "As an example, let's build a ROC curve. We continue with our airport security example. Suppose our classifier returned the following scores (\"+\" represents a true threat, while a high score, close to 1, means a confident prediction that the observation is a threat) for 6 observations :\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1byt8YC6h9klPF2s0lUYZ4rDyo3gJ05A1\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Then we can compute the TPR (=TP/P) and FPR (=FP/P) for every threshold range: \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1hJxvUQKKS5RZzv6FvbKKH7Ua-nsawyDa\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "Which gives us the following ROC curve:\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1dXCxWe5jiEHz_bsf5wXziK8mqJjxEzXX\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# III. Evaluation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.1. Residual Sum of Squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember that we fitted a Regression model by trying to minimize the distance between the model predictions and the data points\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1UmfQle9OImxlTgu3AEUsk9Yvo8RYaVsR\" width=\"100%\">\n",
    "\n",
    "\n",
    "If we sum all the squares of distances (in order to sum only positive values), we obtain the **Residual Sum of Squares**:\n",
    "\n",
    "$${RSS=\\sum _{i=1}^{n}(y_{i}-f(x_{i}))^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.2. (Root) Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to have a \"magnitude of the error\" for one single data point, we can:\n",
    "\n",
    "- Divide the RSS by the number of points (get the mean). This gives us the **Mean Squared Error** (MSE):\n",
    "\n",
    "$${MSE=\\frac{1}{n}\\sum _{i=1}^{n}(y_{i}-f(x_{i}))^{2}}$$\n",
    "\n",
    "- More accurately, as we computed the squares of the residuals, we can take the square root in order to have the same unit as the data points. This gives us the **Root Mean Squared Error** (RMSE):\n",
    "\n",
    "$${RMSE=\\sqrt{\\frac{1}{n}\\sum _{i=1}^{n}(y_{i}-f(x_{i}))^{2}}}$$\n",
    "\n",
    "For example, the RMSE for a home price regression model will be in ‚Ç¨ and will correspond to the mean error of your regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.3. R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, we can compute a new value very useful in regression: $R^2$\n",
    "\n",
    "First, we define the **Relative Squared Error**: \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1TWGTV-uYaoZoLs2-kmFVQqxmjjmDxvfY\" width=\"30%\">\n",
    "</p>\n",
    "\n",
    "Instead of dividing the RSS by the number of points in the dataset (which gives the MSE), we divide the RSS by a \"reasonable\" error: the sum of distances between the data points and the mean.\n",
    "\n",
    "$R^2$ is then defined as $R^2 = 1 - RSE$ and it gives an indication of **how much are the true value and the predicted value correlated?**\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1eAiEwTMjfzobHnW9RUB0YRIPGFbzGy7e\" width=\"70%\">\n",
    "</p>\n",
    "\n",
    "It's value is between 0 and 1 and:\n",
    "- $R^2$ is close to 0 when values are not correlated at all (random noise)\n",
    "- $R^2$ is close to 1 when values are highly correlated (even negatively). This means that knowing one helps a lot knowing the other. \n",
    "\n",
    "> ‚ö†Ô∏è **Warning**: The previous charts do not correspond to the regression chart (relation between output and input). It shows the correlation between true value and predicted value\n",
    "\n",
    "Here is another way of seeing it:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ysIEDMeZ7G43T6_oQOqXYxEsE1-ElMoV\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
