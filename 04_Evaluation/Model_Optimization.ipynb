{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameters and hyperparameters\n",
    "- hyperparameters optimization: the valid dataset\n",
    "- Cross validation\n",
    "- Gridsearch and randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Hyperparameters üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/0*K-0v6zWiCXt2_FHB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Previously, we learnt to prepare our data in order to train machine learning models.\n",
    "\n",
    "Today, we will see that we can *boost* our model results by playing with **hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# I. Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1. Evaluating the performance of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, to evaluate the performance of a model, we have been checking its score on a test set. But this process is actually quite problematic : **in real life, we do not have a test set** ! The test data are actually real life data, for which we do not have a label (e.g. no `y_test`), and we need to get a prediction. And since we do not have a `y_test`, there is no way to compute the score of the model !\n",
    "\n",
    "> üîç For instance, if we need to predict tomorrow's weather, we can train a model with the data from the previous days, and then make a prediction ; but we don't actually know yet what will be tomorrow's weather, and so we have no way to evaluate the accuracy of the model's prediction !\n",
    "\n",
    "That's why we will use the **cross-validation technique**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2. The validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T08:42:29.345854Z",
     "start_time": "2019-07-15T08:42:29.331450Z"
    }
   },
   "source": [
    "We are going to split our data into three different sets :\n",
    "- the training set\n",
    "- the test set\n",
    "- **the validation set**\n",
    "\n",
    "A common split is for example: 60% - 20% - 20%.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ahZYvfiqQumVw-z0FkDVue7Pt9krAGCk\" width=\"400px\">\n",
    "</p>\n",
    "\n",
    "This new **Validation Set** is an other set of observations used to **evaluate the performance of the model**, and then **tune the hyperparameters** (not the weights, but some options given by our model before fitting) of the model. \n",
    "\n",
    "> ‚û°Ô∏è In other words, **the validation set is a subset used for evaluating your model performance along the way in choosing/building the best model**.\n",
    "\n",
    "The validation dataset is commonly noted `X_val` (for the features) and `y_val` (for the corresponding targets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3. The cross-validation technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cross-validation** technique allows you to train (and evaluate your model) on all your labeled data available (except the test set). \n",
    "\n",
    "The process of the cross-validation is the following:\n",
    "- You split your data into a training set and a test set (for example 80%-20%)\n",
    "- You split your training set into `cv` folds (for example `cv`=10 splits)\n",
    "- You train on all folds except one - and you do that `cv` times, keeping each time a different fold aside\n",
    "- For each training you compute your error\n",
    "- The error is then averaged over the k folds and is named **cross-validation error**.\n",
    "\n",
    "This way, **you will have a better understanding of your model performance** - as it **will have seen all data available except test set** for **both training and validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=18iNqOegmMWxGkGbVD2rYPzsH4D97jRNC\" width=\"700px\">\n",
    "</p>\n",
    "\n",
    "> üî¶ **Hint**: This method works great on small to medium-sized datasets (< 10,000 - 100,000 lines). This is however not approprieted for big datasets (> 100,000 - 1M lines depending on your model complexity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3.A. Implementing a K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides an easy tool to split data into a train set and a validation set according to a given number of splits (also called **folds**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:02.892814Z",
     "start_time": "2020-01-29T20:42:02.887505Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand what the `KFold` does, let's work on a very small and fictional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:03.431261Z",
     "start_time": "2020-01-29T20:42:03.426867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's work on fictional data\n",
    "data = np.array([2, 4, 6, 5, 1, 7, 3, 9, 11])               # The features\n",
    "y = np.array(['R', 'R', 'R', 'B', 'B', 'B', 'B', 'B', 'B']) # The target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:03.963773Z",
     "start_time": "2020-01-29T20:42:03.959700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instanciating the KFold object\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è The KFold object returns arrays of **indices**, not of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:04.423648Z",
     "start_time": "2020-01-29T20:42:04.414228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0, 3, 4, 5, 6, 8]), array([1, 2, 7])),\n",
       " (array([0, 1, 2, 3, 5, 7]), array([4, 6, 8])),\n",
       " (array([1, 2, 4, 6, 7, 8]), array([0, 3, 5]))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the results of the kfold split by calling the method `.split()`\n",
    "list(kfold.split(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:04.888263Z",
     "start_time": "2020-01-29T20:42:04.876098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold n¬∞1\n",
      "X_train : [ 2  5  1  7  3 11], y_train : ['R' 'B' 'B' 'B' 'B' 'B']\n",
      "X_val : [4 6 9], y_val : ['R' 'R' 'B']\n",
      "----------\n",
      "Fold n¬∞2\n",
      "X_train : [2 4 6 5 7 9], y_train : ['R' 'R' 'R' 'B' 'B' 'B']\n",
      "X_val : [ 1  3 11], y_val : ['B' 'B' 'B']\n",
      "----------\n",
      "Fold n¬∞3\n",
      "X_train : [ 4  6  1  3  9 11], y_train : ['R' 'R' 'B' 'B' 'B' 'B']\n",
      "X_val : [2 5 7], y_val : ['R' 'B' 'B']\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Looping to see the splitted values\n",
    "counter = 1\n",
    "for train, val in kfold.split(data, y):\n",
    "    print(f\"Fold n¬∞{counter}\")\n",
    "    counter += 1\n",
    "    print(f\"X_train : {data[train]}, y_train : {y[train]}\")\n",
    "    print(f\"X_val : {data[val]}, y_val : {y[val]}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a more visual way : \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1NMSWJv8XMzY8tAM8pVibu_NashNYGhQA\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `KFold` object only gives out the `K` splits of the data. It does not fit and evaluate any model, which is something we have to do ourselves. Thankfully, it is quite easy to do with a simple **for loop** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:05.362737Z",
     "start_time": "2020-01-29T20:42:05.358519Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:43:15.675384Z",
     "start_time": "2020-01-29T20:43:15.663774Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train, val in kfold.split(data, y):\n",
    "    \n",
    "    # Creating the train set and validation set\n",
    "    X_train = data[train].reshape(-1, 1)\n",
    "    y_train = y[train]\n",
    "    X_val = data[val].reshape(-1, 1)\n",
    "    y_val = y[val]\n",
    "    \n",
    "    # Selecting the model, fitting it, and making a prediction\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_val)\n",
    "    \n",
    "    # Filling a list of accuracy scores\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:43:16.099344Z",
     "start_time": "2020-01-29T20:43:16.093144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get a list of the model's scores on each fold\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:43:16.788499Z",
     "start_time": "2020-01-29T20:43:16.783361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean accuracy score gives us a good idea of the performance of our model\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is not very good, which can be explained by two factors :\n",
    "- We are working on very few and fictional data, which doesn't allow for a good performance of our classification model.\n",
    "- More importantly, the K-Fold split is not **stratified**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.B. Implementing a Stratified K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StratifiedKFold` object in `scikit-learn` works exactly like the `KFold`. The only exception is that, when calling the method `.split()`, we need to give it the target (the `y`), as it will use it to create the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:11.894327Z",
     "start_time": "2020-01-29T20:42:11.889722Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:12.350638Z",
     "start_time": "2020-01-29T20:42:12.340575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1, 2, 5, 6, 7, 8]), array([0, 3, 4])),\n",
       " (array([0, 2, 3, 4, 7, 8]), array([1, 5, 6])),\n",
       " (array([0, 1, 3, 4, 5, 6]), array([2, 7, 8]))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StratifiedKFold gives K arrays of indexes\n",
    "list(skfold.split(data, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:13.293636Z",
     "start_time": "2020-01-29T20:42:13.284449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold n¬∞1\n",
      "X_train : [ 4  6  7  3  9 11], y_train : ['R' 'R' 'B' 'B' 'B' 'B']\n",
      "X_val : [2 5 1], y_val : ['R' 'B' 'B']\n",
      "----------\n",
      "Fold n¬∞2\n",
      "X_train : [ 2  6  5  1  9 11], y_train : ['R' 'R' 'B' 'B' 'B' 'B']\n",
      "X_val : [4 7 3], y_val : ['R' 'B' 'B']\n",
      "----------\n",
      "Fold n¬∞3\n",
      "X_train : [2 4 5 1 7 3], y_train : ['R' 'R' 'B' 'B' 'B' 'B']\n",
      "X_val : [ 6  9 11], y_val : ['R' 'B' 'B']\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Looping to see the splitted data\n",
    "counter = 1\n",
    "for train, val in skfold.split(data, y):\n",
    "    print(f\"Fold n¬∞{counter}\")\n",
    "    counter += 1\n",
    "    print(f\"X_train : {data[train]}, y_train : {y[train]}\")\n",
    "    print(f\"X_val : {data[val]}, y_val : {y[val]}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice, compared to the splits created by the `KFold` ?\n",
    "\n",
    "‚û°Ô∏è The splits given by the `StratifiedKFold` object are **stratified**. \n",
    "\n",
    "> From the [Wikipedia definition](https://en.wikipedia.org/wiki/Stratified_sampling) : *Stratification is the process of dividing members of the population into homogeneous subgroups before sampling.*\n",
    "\n",
    "In other words, the `StratifiedKFold` created subgroups that all contain the same repartition of the `\"R\"` and `\"B\"` classes. More importantly, this repartition (1/3 of `\"R\"` and 2/3 of `\"B\"`) is coherent with the initial repartition of classes in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a more visual way :\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1NuwKkKmp0yX2Z3S2q8nMYg32KkBVaBlR\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:22.650597Z",
     "start_time": "2020-01-29T20:42:22.635510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's actually do the cross-validation process now\n",
    "\n",
    "scores = []\n",
    "for train, val in skfold.split(data, y):\n",
    "    \n",
    "    # Creating the train set and validation set\n",
    "    X_train = data[train].reshape(-1, 1)\n",
    "    y_train = y[train]\n",
    "    X_val = data[val].reshape(-1, 1)\n",
    "    y_val = y[val]\n",
    "    \n",
    "    # Fitting the model on the data\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_val)\n",
    "    \n",
    "    # Getting the model's score on each fold\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:23.221862Z",
     "start_time": "2020-01-29T20:42:23.217052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0.6666666666666666, 0.6666666666666666]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get a list of the model's score on each fold\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T20:42:24.159362Z",
     "start_time": "2020-01-29T20:42:24.153955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555555"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean score gives a good idea of the model's performance !\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is better, because we have trained and validated the model on subsets of the data that are actually **representative of the whole dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.C. Recap : `KFold` vs `StratifiedKFold`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1gVp5H4P_ObplwLRZSEiRLSnJrwwpGW9k\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we will **always use the cross-validation technique** in order to evaluate the performance of our model. It is also always better to use a **stratified** method of sub-sampling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do you apply it in order to **find the optimal hyperparameters**? And what do we mean exactly by **hyperparameters**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# II. Previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work on a real dataset. We cleaned our **Titanic dataset**, and saved it in **pickle format**.\n",
    "\n",
    "Let's load it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:42.744590Z",
     "start_time": "2020-01-29T21:21:42.712188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_Val_C</th>\n",
       "      <th>Embarked_Val_Q</th>\n",
       "      <th>Embarked_Val_S</th>\n",
       "      <th>isAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>Title_val_Master.</th>\n",
       "      <th>Title_val_Miss.</th>\n",
       "      <th>Title_val_Mr.</th>\n",
       "      <th>Title_val_Mrs.</th>\n",
       "      <th>Title_val_Rare_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "\n",
       "             Ticket     Fare  ... Embarked_Val_C  Embarked_Val_Q  \\\n",
       "0         A/5 21171   7.2500  ...              0               0   \n",
       "1          PC 17599  71.2833  ...              1               0   \n",
       "2  STON/O2. 3101282   7.9250  ...              0               0   \n",
       "\n",
       "   Embarked_Val_S  isAlone  Title Title_val_Master.  Title_val_Miss.  \\\n",
       "0               1        0    Mr.                 0                0   \n",
       "1               0        0   Mrs.                 0                0   \n",
       "2               1        1  Miss.                 0                1   \n",
       "\n",
       "   Title_val_Mr.  Title_val_Mrs.  Title_val_Rare_Title  \n",
       "0              1               0                     0  \n",
       "1              0               1                     0  \n",
       "2              0               0                     0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "data_path = os.path.join(\"..\", \"..\", \"05-Data-Preparation\", \"00-Lectures\", \"data_cleaned.pkl\")\n",
    "\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_cleaned = pickle.load(f)\n",
    "\n",
    "data_cleaned.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:43.164207Z",
     "start_time": "2020-01-29T21:21:43.159518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Picking the columns we want to work on\n",
    "features_to_use = [\"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Parch\",\n",
    "                   \"Sex\", \"Embarked_Val_C\", \"Embarked_Val_Q\",\n",
    "                   \"isAlone\", \"Title_val_Mr.\", \"Title_val_Mrs.\",\n",
    "                   \"Title_val_Rare_Title\", \"Title_val_Miss.\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:43.621027Z",
     "start_time": "2020-01-29T21:21:43.611319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the features X and the target y\n",
    "X = data_cleaned[features_to_use]\n",
    "y = data_cleaned['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1. Let's use the cross-validation technique to evaluate the performance of a SVM classifier on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:44.352918Z",
     "start_time": "2020-01-29T21:21:44.347558Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we still need to split our dataset with a `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T22:04:50.909619Z",
     "start_time": "2020-01-29T22:04:50.902285Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the performance of our model with a cross-validation.\n",
    "\n",
    "‚ùìBut do we apply the cross validation on `X` or on `X_train` ?\n",
    "\n",
    "‚û°Ô∏è The cross validation is **always applied to the training set**. **The test set must remain unseen** until the very end of the process, the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:47.026251Z",
     "start_time": "2020-01-29T21:21:46.900656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cross val with a SVC\n",
    "# Let's use the StratifiedKFold right away\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores = []\n",
    "for train, val in skfold.split(X_train, y_train):\n",
    "    \n",
    "    # Creating the train set and validation set\n",
    "    X_train_val = X_train.iloc[train]\n",
    "    y_train_val = y_train.iloc[train]\n",
    "    X_val = X_train.iloc[val]\n",
    "    y_val = y_train.iloc[val]\n",
    "    \n",
    "    # Fitting the model on the data\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_val, y_train_val)\n",
    "    y_pred = svc.predict(X_val)\n",
    "    \n",
    "    # Getting the model's score on each fold\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:48.224049Z",
     "start_time": "2020-01-29T21:21:48.214940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7440220652387268"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain an accuracy score of 74.4% with a SVC.\n",
    "Let's improve that score !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# III. Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reading the scikit-learn documentation for [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), we observe that the model can take various optional parameters.\n",
    "\n",
    "For example `C`, `kernel`, etc.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1AeUUZSyCwYvc-mwzOBH4exV0ZvyL3WZq\" width=\"100%\">\n",
    "\n",
    "We call them **hyperparameters**.\n",
    "\n",
    "> üî¶ **Hint**: Hyperparameters are parameters that are not directly learnt by the model. They are passed as arguments to the model constructor. It is like \"options‚Äú/settings of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the hyperparameter C=1.0\n",
    "\n",
    "What if we retrained our model with a new values of C? With C=0.1 ? C=10? C=100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:21:51.970203Z",
     "start_time": "2020-01-29T21:21:51.099054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1\n",
      "Mean accuracy on 5 folds : 0.6244779693386227\n",
      "C=1\n",
      "Mean accuracy on 5 folds : 0.7440220652387268\n",
      "C=10\n",
      "Mean accuracy on 5 folds : 0.753851951664358\n",
      "C=100\n",
      "Mean accuracy on 5 folds : 0.7412248624415241\n",
      "C=1000\n",
      "Mean accuracy on 5 folds : 0.7312562474983811\n"
     ]
    }
   ],
   "source": [
    "# Looping through different values of the parameter `C`\n",
    "# And still evaluating the results with a cross-validation\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)  # Let's use stratification right away\n",
    "\n",
    "for C in [0.1, 1, 10, 100, 1000]:\n",
    "    print(f\"C={C}\")\n",
    "    scores = []\n",
    "    \n",
    "    for train, val in skfold.split(X_train, y_train):\n",
    "        # Creating the train set and the validation set\n",
    "        X_train_val = X_train.iloc[train]\n",
    "        y_train_val = y_train.iloc[train]\n",
    "        X_val = X_train.iloc[val]\n",
    "        y_val = y_train.iloc[val]\n",
    "        \n",
    "        # Fitting the model with a varying `C` parameter on the data\n",
    "        svc = SVC(C=C)\n",
    "        svc.fit(X_train_val, y_train_val)\n",
    "        y_pred = svc.predict(X_val)\n",
    "        \n",
    "        # Getting the scores\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        scores.append(acc)\n",
    "    \n",
    "    print(f\"Mean accuracy on 5 folds : {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy changes! In our case, setting the value of `C` to 10 leads to an **increase of the accuracy**. Interesting.. üòè\n",
    "\n",
    "This could mean we can **search for the optimal values of hyperparameters** (that maximize the accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## III.1. Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model can take some time, and we do not want to test all possible values of hyperparameters in order to find the optimal ones (this would be too consuming - in time and energy).\n",
    "\n",
    "Instead, we could **follow a search strategy** such as: \n",
    "- Testing different specified combinations, also called `GridSearchCV`\n",
    "- Testing hyperparameters randomly, also called `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.2. `GridSearchCV`: Exhaustive Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search provided by `GridSearchCV` exhaustively generates candidates from a grid of parameter values specified with the `param_grid` parameter.\n",
    "\n",
    "For instance, the following `param_grid`:\n",
    "\n",
    "``` python\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "```\n",
    "\n",
    "specifies that two grids should be explored:\n",
    "- one with a **linear kernel** and **C** values in [1, 10, 100, 1000]\n",
    "- a second one with an **RBF kernel**, and the cross-product of **C** values ranging in [1, 10, 100, 1000] and **gamma** values in [0.001, 0.0001]\n",
    "\n",
    "When searching for the hyperparameters, we use the training set and the **cross_validation** technique for choosing the optimal hyperparameters - hence the `CV` at the end of the method name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:11.898398Z",
     "start_time": "2020-01-29T21:22:11.473379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.001, 0.01, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1, 10, 100], \n",
    "              'gamma': [0.001, 0.01, 0.1]}\n",
    "\n",
    "clf = SVC()\n",
    "grid = GridSearchCV(clf,\n",
    "                   param_grid,\n",
    "                   cv=3, # In order to test the different hyperparameters (on the train set), \n",
    "                         # we use the `cross validation` technique.\n",
    "                         # 3 represents the number of folds of the cross-val.\n",
    "                   verbose=1,  # Setting Verbose adds some \"prints\" (logs) detailing\n",
    "                   n_jobs=-1    # what is happening in backend\n",
    "                                # The higher the setting, the higher the nb of logs printed\n",
    "                  )\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### All results: `cv_results_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I want to retrieve the best hyperparameters found by the grid search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:14.793789Z",
     "start_time": "2020-01-29T21:22:14.781731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.013304  , 0.01612131, 0.02281213, 0.01000094, 0.01259081,\n",
       "        0.02087164, 0.02064967, 0.02612297, 0.02734367]),\n",
       " 'std_fit_time': array([0.00229677, 0.00048986, 0.0007653 , 0.00125901, 0.00064471,\n",
       "        0.00408818, 0.00380952, 0.0033561 , 0.00799329]),\n",
       " 'mean_score_time': array([0.00608134, 0.00878922, 0.00975386, 0.00394114, 0.00394376,\n",
       "        0.00563534, 0.00261768, 0.00288335, 0.00463994]),\n",
       " 'std_score_time': array([5.00377837e-04, 2.38371811e-03, 4.68590354e-03, 8.98845871e-04,\n",
       "        1.16538358e-03, 1.94929950e-03, 7.79261277e-05, 2.58881544e-05,\n",
       "        7.65181078e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 10, 10, 10, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.001, 0.01, 0.1, 0.001, 0.01, 0.1, 0.001, 0.01, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'gamma': 0.001},\n",
       "  {'C': 1, 'gamma': 0.01},\n",
       "  {'C': 1, 'gamma': 0.1},\n",
       "  {'C': 10, 'gamma': 0.001},\n",
       "  {'C': 10, 'gamma': 0.01},\n",
       "  {'C': 10, 'gamma': 0.1},\n",
       "  {'C': 100, 'gamma': 0.001},\n",
       "  {'C': 100, 'gamma': 0.01},\n",
       "  {'C': 100, 'gamma': 0.1}],\n",
       " 'split0_test_score': array([0.74683544, 0.71729958, 0.74261603, 0.82278481, 0.80168776,\n",
       "        0.7257384 , 0.83966245, 0.80590717, 0.73839662]),\n",
       " 'split1_test_score': array([0.70886076, 0.73839662, 0.71729958, 0.82700422, 0.76371308,\n",
       "        0.70464135, 0.81012658, 0.75105485, 0.71308017]),\n",
       " 'split2_test_score': array([0.64978903, 0.68776371, 0.72995781, 0.78902954, 0.7721519 ,\n",
       "        0.72995781, 0.78902954, 0.78059072, 0.70886076]),\n",
       " 'mean_test_score': array([0.70182841, 0.71448664, 0.72995781, 0.81293952, 0.77918425,\n",
       "        0.72011252, 0.81293952, 0.77918425, 0.72011252]),\n",
       " 'std_test_score': array([0.03992987, 0.02076628, 0.0103354 , 0.01699444, 0.01628106,\n",
       "        0.01107455, 0.02076628, 0.02241544, 0.01304306]),\n",
       " 'rank_test_score': array([9, 8, 5, 1, 3, 6, 1, 3, 6], dtype=int32)}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:16.569077Z",
     "start_time": "2020-01-29T21:22:16.543254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.649789</td>\n",
       "      <td>0.701828</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016121</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.717300</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>0.687764</td>\n",
       "      <td>0.714487</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022812</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.742616</td>\n",
       "      <td>0.717300</td>\n",
       "      <td>0.729958</td>\n",
       "      <td>0.729958</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.812940</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012591</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.801688</td>\n",
       "      <td>0.763713</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.779184</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020872</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.725738</td>\n",
       "      <td>0.704641</td>\n",
       "      <td>0.729958</td>\n",
       "      <td>0.720113</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.812940</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.805907</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.780591</td>\n",
       "      <td>0.779184</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>0.713080</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.720113</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.013304      0.002297         0.006081        0.000500       1   \n",
       "1       0.016121      0.000490         0.008789        0.002384       1   \n",
       "2       0.022812      0.000765         0.009754        0.004686       1   \n",
       "3       0.010001      0.001259         0.003941        0.000899      10   \n",
       "4       0.012591      0.000645         0.003944        0.001165      10   \n",
       "5       0.020872      0.004088         0.005635        0.001949      10   \n",
       "6       0.020650      0.003810         0.002618        0.000078     100   \n",
       "7       0.026123      0.003356         0.002883        0.000026     100   \n",
       "8       0.027344      0.007993         0.004640        0.000765     100   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0       0.001    {'C': 1, 'gamma': 0.001}           0.746835   \n",
       "1        0.01     {'C': 1, 'gamma': 0.01}           0.717300   \n",
       "2         0.1      {'C': 1, 'gamma': 0.1}           0.742616   \n",
       "3       0.001   {'C': 10, 'gamma': 0.001}           0.822785   \n",
       "4        0.01    {'C': 10, 'gamma': 0.01}           0.801688   \n",
       "5         0.1     {'C': 10, 'gamma': 0.1}           0.725738   \n",
       "6       0.001  {'C': 100, 'gamma': 0.001}           0.839662   \n",
       "7        0.01   {'C': 100, 'gamma': 0.01}           0.805907   \n",
       "8         0.1    {'C': 100, 'gamma': 0.1}           0.738397   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.708861           0.649789         0.701828        0.039930   \n",
       "1           0.738397           0.687764         0.714487        0.020766   \n",
       "2           0.717300           0.729958         0.729958        0.010335   \n",
       "3           0.827004           0.789030         0.812940        0.016994   \n",
       "4           0.763713           0.772152         0.779184        0.016281   \n",
       "5           0.704641           0.729958         0.720113        0.011075   \n",
       "6           0.810127           0.789030         0.812940        0.020766   \n",
       "7           0.751055           0.780591         0.779184        0.022415   \n",
       "8           0.713080           0.708861         0.720113        0.013043   \n",
       "\n",
       "   rank_test_score  \n",
       "0                9  \n",
       "1                8  \n",
       "2                5  \n",
       "3                1  \n",
       "4                3  \n",
       "5                6  \n",
       "6                1  \n",
       "7                3  \n",
       "8                6  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To visualize these cv_results more easily, we can transform the dict into a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Optimal hyperparameters: `best_params_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:19.593374Z",
     "start_time": "2020-01-29T21:22:19.585809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Best score found (mean score on all folds used as validation set): `best_score_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:21.918581Z",
     "start_time": "2020-01-29T21:22:21.912429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70182841, 0.71448664, 0.72995781, 0.81293952, 0.77918425,\n",
       "       0.72011252, 0.81293952, 0.77918425, 0.72011252])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the mean scores found for each point of the param_grid\n",
    "grid.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:22.609319Z",
     "start_time": "2020-01-29T21:22:22.602852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129395218002813"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best score found\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Best estimator: `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:24.978893Z",
     "start_time": "2020-01-29T21:22:24.974093Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Hyperparameters tested: `param_grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:26.937665Z",
     "start_time": "2020-01-29T21:22:26.930305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [1, 10, 100], 'gamma': [0.001, 0.01, 0.1]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.3. `RandomizedSearchCV` : Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. \n",
    "\n",
    "**`RandomizedSearchCV` implements a randomized search over parameters**, where **each setting is sampled from a distribution of possible parameter values**. This has two main benefits over an exhaustive search:\n",
    "- A budget (e.g. a number of search iterations) can be chosen independently of the number of parameters and possible values\n",
    "- Adding parameters that do not influence the performance does not decrease efficiency\n",
    "\n",
    "Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for `GridSearchCV`. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the `n_iter` parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:\n",
    "\n",
    "``` python\n",
    "random_grid = {\n",
    "    'C': scipy.stats.expon(scale=100),\n",
    "    'gamma': scipy.stats.expon(scale=.1),\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "```\n",
    "\n",
    "This example uses the `scipy.stats` module, which contains many useful distributions for sampling parameters, such as expon, gamma, uniform or randint. In principle, any function can be passed that provides a rvs (random variate sample) method to sample a value. A call to the rvs function should provide independent random samples from possible parameter values on consecutive calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üî¶ **Hint**: In contrast to `GridSearchCV`, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by `n_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:23:55.734127Z",
     "start_time": "2020-01-29T21:23:51.816855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                 coef0=0.0, decision_function_shape='ovr',\n",
       "                                 degree=3, gamma='auto_deprecated',\n",
       "                                 kernel='rbf', max_iter=-1, probability=False,\n",
       "                                 random_state=None, shrinking=True, tol=0.001,\n",
       "                                 verbose=False),\n",
       "                   iid='warn', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a23beca20>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a23becbe0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "param_dist = {\n",
    "    'C': scipy.stats.expon(scale=100),\n",
    "    'gamma': scipy.stats.expon(scale=.1)\n",
    "    }\n",
    "\n",
    "n_iter_search = 50 # n_iter is the number of hyperparameters settings that are tried\n",
    "grid = RandomizedSearchCV(clf,\n",
    "                         param_distributions=param_dist,\n",
    "                         n_iter=n_iter_search,\n",
    "                         verbose=1,\n",
    "                         cv=5, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can retrieve all information from our classifier search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### All results: `cv_results_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I want to retrieve the best hyperparameters found by the random search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:24:19.370834Z",
     "start_time": "2020-01-29T21:24:19.347184Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.04259734, 0.05489106, 0.08129706, 0.06270065, 0.03509617,\n",
       "        0.0495028 , 0.04700789, 0.05259528, 0.0507885 , 0.0670177 ,\n",
       "        0.05155001, 0.04905071, 0.04042497, 0.05466361, 0.06375461,\n",
       "        0.06093712, 0.05347896, 0.11769476, 0.03962045, 0.05049601,\n",
       "        0.03568912, 0.06046133, 0.05123944, 0.01982584, 0.07772617,\n",
       "        0.05772867, 0.03116751, 0.05205765, 0.0683208 , 0.05970421,\n",
       "        0.05134821, 0.05301933, 0.07111435, 0.03898697, 0.08681226,\n",
       "        0.04507689, 0.03253412, 0.04118514, 0.03665118, 0.07701507,\n",
       "        0.05429244, 0.07025409, 0.0600204 , 0.07002354, 0.05429382,\n",
       "        0.0431911 , 0.08901358, 0.02432766, 0.04371715, 0.03723125]),\n",
       " 'std_fit_time': array([0.00893756, 0.01205306, 0.01507677, 0.0185296 , 0.0052873 ,\n",
       "        0.01155773, 0.00870881, 0.01092525, 0.01473729, 0.01542342,\n",
       "        0.01083921, 0.01876623, 0.00788362, 0.01099752, 0.01208729,\n",
       "        0.0142953 , 0.01268239, 0.04385797, 0.002584  , 0.0110039 ,\n",
       "        0.00242879, 0.01173379, 0.00608271, 0.00184066, 0.02301178,\n",
       "        0.00884084, 0.00163424, 0.01386231, 0.01423891, 0.01195351,\n",
       "        0.01271549, 0.01071472, 0.01325901, 0.0079367 , 0.02952275,\n",
       "        0.00896971, 0.00137451, 0.00593599, 0.00499728, 0.02744974,\n",
       "        0.02256469, 0.02424756, 0.01271152, 0.01106482, 0.01485924,\n",
       "        0.00561759, 0.03159038, 0.00428686, 0.00983404, 0.0070278 ]),\n",
       " 'mean_score_time': array([0.00663905, 0.00759373, 0.00410671, 0.00491781, 0.00460734,\n",
       "        0.00463314, 0.00578322, 0.00470719, 0.003509  , 0.00385137,\n",
       "        0.00445704, 0.00485339, 0.00463905, 0.00466771, 0.00429149,\n",
       "        0.00424962, 0.00515075, 0.00461583, 0.00440159, 0.00425301,\n",
       "        0.00463643, 0.00525994, 0.00578132, 0.0043097 , 0.00378647,\n",
       "        0.00398555, 0.00553441, 0.00542264, 0.00393   , 0.00439053,\n",
       "        0.0039454 , 0.00413222, 0.00394425, 0.00419683, 0.00399613,\n",
       "        0.00526295, 0.00498815, 0.00457711, 0.00404758, 0.00460157,\n",
       "        0.00430222, 0.00501995, 0.00667582, 0.00967288, 0.00589366,\n",
       "        0.00459313, 0.00456429, 0.00294838, 0.00459957, 0.00406876]),\n",
       " 'std_score_time': array([2.57723689e-03, 2.49870119e-03, 1.08199321e-04, 5.96878470e-04,\n",
       "        1.97251551e-04, 2.02446515e-04, 3.00110404e-03, 1.31857786e-03,\n",
       "        1.86938071e-04, 1.62561361e-04, 8.50872319e-05, 3.01616393e-04,\n",
       "        7.60467219e-05, 6.29035826e-04, 5.87866412e-04, 2.65489827e-04,\n",
       "        5.26407132e-04, 1.28001922e-03, 4.61990580e-04, 1.95162907e-04,\n",
       "        1.75261470e-04, 2.31532551e-03, 2.36379126e-03, 1.40340912e-04,\n",
       "        2.35781611e-04, 5.71971289e-05, 1.11392809e-03, 1.82005825e-03,\n",
       "        5.99252596e-04, 3.42753037e-04, 3.31041085e-05, 1.23492023e-04,\n",
       "        2.42845005e-04, 3.93904535e-04, 1.55412488e-04, 1.67254072e-03,\n",
       "        3.62104826e-04, 1.47806167e-04, 1.30119451e-04, 9.86923225e-04,\n",
       "        3.71765056e-04, 7.32093501e-04, 2.63130870e-03, 4.52125744e-03,\n",
       "        3.24410417e-03, 1.04328004e-04, 1.81016226e-03, 7.04929784e-04,\n",
       "        1.35011962e-03, 6.02970713e-04]),\n",
       " 'param_C': masked_array(data=[80.2935137080301, 39.04351128038415,\n",
       "                    245.45585366299915, 370.9778248090139,\n",
       "                    10.294138621809873, 118.38023034763663,\n",
       "                    45.1077078274963, 59.014086260510545,\n",
       "                    155.32250835495762, 137.42918832341846,\n",
       "                    187.13160781824533, 244.53425156073413,\n",
       "                    142.22713504520578, 107.33305595782623,\n",
       "                    71.11969786931014, 184.6284713996864,\n",
       "                    62.49699863302817, 358.96894827747974,\n",
       "                    30.731830301168895, 36.87980809055211,\n",
       "                    9.01406262515954, 181.47336348016066,\n",
       "                    205.27538360004627, 15.28272333136626,\n",
       "                    157.08279407258055, 74.19773891301706,\n",
       "                    4.79352025177836, 250.31983205665404,\n",
       "                    237.79994739341683, 137.8497941828178,\n",
       "                    58.07144287756923, 51.53495288037573,\n",
       "                    183.41984217724135, 16.54873754759791,\n",
       "                    168.40351522586909, 66.10629468978436,\n",
       "                    14.443496644393827, 33.986241999458905,\n",
       "                    22.194218582185464, 62.790103550388444,\n",
       "                    72.37183605984676, 322.61525217857934,\n",
       "                    18.375436796812387, 140.99614977607695,\n",
       "                    187.70638263811554, 59.05889182461031,\n",
       "                    138.3884406386705, 40.59856670561383,\n",
       "                    28.66882498679373, 89.49153226055166],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.20103880672824104, 0.121244186622951,\n",
       "                    0.04338983069845184, 0.12304720248008408,\n",
       "                    0.16587048857807607, 0.14423484321104416,\n",
       "                    0.08577075929150187, 0.042492716414554293,\n",
       "                    0.0013170314227432364, 0.01108803640012046,\n",
       "                    0.12507600948102865, 0.26651155240808855,\n",
       "                    0.24390195767228093, 0.08317033423793069,\n",
       "                    0.015357227591559287, 0.05795197283336863,\n",
       "                    0.0848542469845919, 0.03968245448370117,\n",
       "                    0.031723698870032804, 0.03684068006228509,\n",
       "                    0.14353524323321018, 0.05674747809522532,\n",
       "                    0.17325166776361445, 0.00042479834830309215,\n",
       "                    0.01668156812090071, 0.037459328653615336,\n",
       "                    0.31152024922661975, 0.1774008408591914,\n",
       "                    0.0573349122073757, 0.08047563220343928,\n",
       "                    0.026115180213283858, 0.05876913878103172,\n",
       "                    0.04927989708953139, 0.09331506934538736,\n",
       "                    0.011806744576175934, 0.09629819101414774,\n",
       "                    0.2642817587023386, 0.11557375446033685,\n",
       "                    0.020064763555719723, 0.0189785753781382,\n",
       "                    0.006669769287736373, 0.13964400014027942,\n",
       "                    0.043671404199583146, 0.10763168215028121,\n",
       "                    0.146233837822299, 0.12587851120175453,\n",
       "                    0.019846713015187062, 0.010296955380330335,\n",
       "                    0.0714001982981633, 0.15759846421798085],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 80.2935137080301, 'gamma': 0.20103880672824104},\n",
       "  {'C': 39.04351128038415, 'gamma': 0.121244186622951},\n",
       "  {'C': 245.45585366299915, 'gamma': 0.04338983069845184},\n",
       "  {'C': 370.9778248090139, 'gamma': 0.12304720248008408},\n",
       "  {'C': 10.294138621809873, 'gamma': 0.16587048857807607},\n",
       "  {'C': 118.38023034763663, 'gamma': 0.14423484321104416},\n",
       "  {'C': 45.1077078274963, 'gamma': 0.08577075929150187},\n",
       "  {'C': 59.014086260510545, 'gamma': 0.042492716414554293},\n",
       "  {'C': 155.32250835495762, 'gamma': 0.0013170314227432364},\n",
       "  {'C': 137.42918832341846, 'gamma': 0.01108803640012046},\n",
       "  {'C': 187.13160781824533, 'gamma': 0.12507600948102865},\n",
       "  {'C': 244.53425156073413, 'gamma': 0.26651155240808855},\n",
       "  {'C': 142.22713504520578, 'gamma': 0.24390195767228093},\n",
       "  {'C': 107.33305595782623, 'gamma': 0.08317033423793069},\n",
       "  {'C': 71.11969786931014, 'gamma': 0.015357227591559287},\n",
       "  {'C': 184.6284713996864, 'gamma': 0.05795197283336863},\n",
       "  {'C': 62.49699863302817, 'gamma': 0.0848542469845919},\n",
       "  {'C': 358.96894827747974, 'gamma': 0.03968245448370117},\n",
       "  {'C': 30.731830301168895, 'gamma': 0.031723698870032804},\n",
       "  {'C': 36.87980809055211, 'gamma': 0.03684068006228509},\n",
       "  {'C': 9.01406262515954, 'gamma': 0.14353524323321018},\n",
       "  {'C': 181.47336348016066, 'gamma': 0.05674747809522532},\n",
       "  {'C': 205.27538360004627, 'gamma': 0.17325166776361445},\n",
       "  {'C': 15.28272333136626, 'gamma': 0.00042479834830309215},\n",
       "  {'C': 157.08279407258055, 'gamma': 0.01668156812090071},\n",
       "  {'C': 74.19773891301706, 'gamma': 0.037459328653615336},\n",
       "  {'C': 4.79352025177836, 'gamma': 0.31152024922661975},\n",
       "  {'C': 250.31983205665404, 'gamma': 0.1774008408591914},\n",
       "  {'C': 237.79994739341683, 'gamma': 0.0573349122073757},\n",
       "  {'C': 137.8497941828178, 'gamma': 0.08047563220343928},\n",
       "  {'C': 58.07144287756923, 'gamma': 0.026115180213283858},\n",
       "  {'C': 51.53495288037573, 'gamma': 0.05876913878103172},\n",
       "  {'C': 183.41984217724135, 'gamma': 0.04927989708953139},\n",
       "  {'C': 16.54873754759791, 'gamma': 0.09331506934538736},\n",
       "  {'C': 168.40351522586909, 'gamma': 0.011806744576175934},\n",
       "  {'C': 66.10629468978436, 'gamma': 0.09629819101414774},\n",
       "  {'C': 14.443496644393827, 'gamma': 0.2642817587023386},\n",
       "  {'C': 33.986241999458905, 'gamma': 0.11557375446033685},\n",
       "  {'C': 22.194218582185464, 'gamma': 0.020064763555719723},\n",
       "  {'C': 62.790103550388444, 'gamma': 0.0189785753781382},\n",
       "  {'C': 72.37183605984676, 'gamma': 0.006669769287736373},\n",
       "  {'C': 322.61525217857934, 'gamma': 0.13964400014027942},\n",
       "  {'C': 18.375436796812387, 'gamma': 0.043671404199583146},\n",
       "  {'C': 140.99614977607695, 'gamma': 0.10763168215028121},\n",
       "  {'C': 187.70638263811554, 'gamma': 0.146233837822299},\n",
       "  {'C': 59.05889182461031, 'gamma': 0.12587851120175453},\n",
       "  {'C': 138.3884406386705, 'gamma': 0.019846713015187062},\n",
       "  {'C': 40.59856670561383, 'gamma': 0.010296955380330335},\n",
       "  {'C': 28.66882498679373, 'gamma': 0.0714001982981633},\n",
       "  {'C': 89.49153226055166, 'gamma': 0.15759846421798085}],\n",
       " 'split0_test_score': array([0.75524476, 0.72727273, 0.72727273, 0.72027972, 0.71328671,\n",
       "        0.72027972, 0.71328671, 0.74125874, 0.81118881, 0.74125874,\n",
       "        0.70629371, 0.70629371, 0.72727273, 0.70629371, 0.74125874,\n",
       "        0.73426573, 0.71328671, 0.74125874, 0.72727273, 0.72027972,\n",
       "        0.6993007 , 0.73426573, 0.72727273, 0.82517483, 0.74125874,\n",
       "        0.73426573, 0.72027972, 0.72027972, 0.72027972, 0.70629371,\n",
       "        0.72727273, 0.74125874, 0.74125874, 0.72727273, 0.73426573,\n",
       "        0.71328671, 0.74125874, 0.72027972, 0.79020979, 0.74125874,\n",
       "        0.76923077, 0.72727273, 0.73426573, 0.72727273, 0.71328671,\n",
       "        0.73426573, 0.73426573, 0.77622378, 0.72027972, 0.72727273]),\n",
       " 'split1_test_score': array([0.77622378, 0.78321678, 0.82517483, 0.78321678, 0.77622378,\n",
       "        0.79020979, 0.81818182, 0.82517483, 0.88111888, 0.84615385,\n",
       "        0.78321678, 0.76223776, 0.76923077, 0.7972028 , 0.86013986,\n",
       "        0.81818182, 0.81818182, 0.82517483, 0.83216783, 0.83216783,\n",
       "        0.77622378, 0.81818182, 0.76923077, 0.88111888, 0.84615385,\n",
       "        0.83216783, 0.75524476, 0.76923077, 0.81118881, 0.79020979,\n",
       "        0.83216783, 0.82517483, 0.81118881, 0.81118881, 0.82517483,\n",
       "        0.7972028 , 0.76923077, 0.78321678, 0.85314685, 0.86013986,\n",
       "        0.83216783, 0.78321678, 0.83916084, 0.79020979, 0.78321678,\n",
       "        0.78321678, 0.83216783, 0.84615385, 0.81818182, 0.79020979]),\n",
       " 'split2_test_score': array([0.74647887, 0.75352113, 0.73943662, 0.74647887, 0.74647887,\n",
       "        0.74647887, 0.73943662, 0.76760563, 0.79577465, 0.79577465,\n",
       "        0.73943662, 0.74647887, 0.74647887, 0.75352113, 0.80985915,\n",
       "        0.73239437, 0.73943662, 0.74647887, 0.78873239, 0.77464789,\n",
       "        0.75352113, 0.73239437, 0.75352113, 0.81690141, 0.78169014,\n",
       "        0.77464789, 0.75352113, 0.75352113, 0.75352113, 0.74647887,\n",
       "        0.79577465, 0.73239437, 0.73239437, 0.73943662, 0.80985915,\n",
       "        0.74647887, 0.73943662, 0.74647887, 0.78873239, 0.8028169 ,\n",
       "        0.83098592, 0.74647887, 0.78873239, 0.73943662, 0.73943662,\n",
       "        0.76056338, 0.78873239, 0.83802817, 0.73239437, 0.73943662]),\n",
       " 'split3_test_score': array([0.64084507, 0.65492958, 0.67605634, 0.66197183, 0.66901408,\n",
       "        0.64084507, 0.65492958, 0.66901408, 0.75352113, 0.73943662,\n",
       "        0.64788732, 0.63380282, 0.64788732, 0.66197183, 0.74647887,\n",
       "        0.66901408, 0.65492958, 0.68309859, 0.70422535, 0.67605634,\n",
       "        0.65492958, 0.66901408, 0.63380282, 0.73943662, 0.73239437,\n",
       "        0.68309859, 0.67605634, 0.63380282, 0.66901408, 0.66197183,\n",
       "        0.70422535, 0.66901408, 0.66197183, 0.66197183, 0.73239437,\n",
       "        0.66197183, 0.64084507, 0.65492958, 0.71830986, 0.72535211,\n",
       "        0.74647887, 0.64084507, 0.67605634, 0.65492958, 0.65492958,\n",
       "        0.64084507, 0.73239437, 0.73239437, 0.67605634, 0.64084507]),\n",
       " 'split4_test_score': array([0.75886525, 0.77304965, 0.80851064, 0.74468085, 0.76595745,\n",
       "        0.75177305, 0.78014184, 0.80851064, 0.82978723, 0.82978723,\n",
       "        0.75177305, 0.76595745, 0.76595745, 0.77304965, 0.84397163,\n",
       "        0.78014184, 0.78014184, 0.80141844, 0.82269504, 0.82269504,\n",
       "        0.75886525, 0.78014184, 0.72340426, 0.79432624, 0.81560284,\n",
       "        0.80851064, 0.77304965, 0.72340426, 0.78723404, 0.77304965,\n",
       "        0.82269504, 0.79432624, 0.78723404, 0.78723404, 0.83687943,\n",
       "        0.78014184, 0.77304965, 0.78723404, 0.83687943, 0.83687943,\n",
       "        0.81560284, 0.73758865, 0.82978723, 0.75886525, 0.75177305,\n",
       "        0.75886525, 0.80141844, 0.82269504, 0.80141844, 0.75177305]),\n",
       " 'mean_test_score': array([0.73558368, 0.73839662, 0.75527426, 0.73136428, 0.73417722,\n",
       "        0.72995781, 0.74120956, 0.76230661, 0.81434599, 0.79043601,\n",
       "        0.7257384 , 0.72292546, 0.73136428, 0.73839662, 0.80028129,\n",
       "        0.74683544, 0.74120956, 0.75949367, 0.77496484, 0.76511955,\n",
       "        0.72855134, 0.74683544, 0.72151899, 0.81153305, 0.78340366,\n",
       "        0.76652602, 0.73558368, 0.72011252, 0.74824191, 0.73558368,\n",
       "        0.77637131, 0.75246132, 0.74683544, 0.74542897, 0.78762307,\n",
       "        0.73980309, 0.73277075, 0.73839662, 0.79746835, 0.79324895,\n",
       "        0.79887482, 0.72714487, 0.77355837, 0.73417722, 0.72855134,\n",
       "        0.73558368, 0.77777778, 0.80309423, 0.74964838, 0.72995781]),\n",
       " 'std_test_score': array([0.04830821, 0.04587082, 0.05482591, 0.04009955, 0.03901171,\n",
       "        0.0498383 , 0.05600351, 0.05523811, 0.04187844, 0.0440798 ,\n",
       "        0.04607451, 0.04930336, 0.04434432, 0.04850913, 0.04895189,\n",
       "        0.05026665, 0.05600351, 0.04982503, 0.05103565, 0.0597351 ,\n",
       "        0.04492704, 0.05026665, 0.04697241, 0.0459772 , 0.04330169,\n",
       "        0.05318594, 0.034281  , 0.04688369, 0.05014877, 0.04644352,\n",
       "        0.05149069, 0.05392003, 0.05140848, 0.05177695, 0.04522493,\n",
       "        0.04843038, 0.04795994, 0.04845072, 0.0469981 , 0.05253613,\n",
       "        0.03477639, 0.0470752 , 0.06121879, 0.04496351, 0.04313932,\n",
       "        0.04981319, 0.03901186, 0.04285253, 0.05282727, 0.04929401]),\n",
       " 'rank_test_score': array([33, 30, 19, 40, 37, 42, 27, 17,  1,  8, 47, 48, 40, 30,  4, 23, 27,\n",
       "        18, 13, 16, 44, 23, 49,  2, 10, 15, 33, 50, 22, 33, 12, 20, 23, 26,\n",
       "         9, 29, 39, 30,  6,  7,  5, 46, 14, 37, 44, 33, 11,  3, 21, 42],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Optimal hyperparameters: `best_params_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially, we can check for the best hyperparameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:24:21.439733Z",
     "start_time": "2020-01-29T21:24:21.433591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 155.32250835495762, 'gamma': 0.0013170314227432364}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Best score found (mean score on all folds used as validation set): `best_score_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:24:23.488637Z",
     "start_time": "2020-01-29T21:24:23.482433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8143459915611815"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Best estimator: `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T21:22:52.536776Z",
     "start_time": "2020-01-29T21:22:52.528603Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=77.81749106356084, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.013763799748375237,\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III.4. `GridSearchCV` vs `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, people are more likely to choose to work with a GridSearch rather than a RandomizedSearch, probably because it seems less \"scary\" : humans do not like random things.\n",
    "\n",
    "But in reality, the RandomizedSearch has several advantages over the GridSearch :\n",
    "- In terms of **computational time**, the main drawback of the GridSearch is that it suffers when the number of hyperparameters grows. With as few as four parameters, this problem can become highly impractical, because the number of evaluations required for this strategy increases exponentially with each additional parameter. The RandomizedSearch does not have the same problem, since we can choose precisely the number of iterations of the search (with the parameter `n_iter`).\n",
    "- In terms of **finding the optimal combinations of hyperparameters**, the RandomizedSearch is more likely to find an optimal combination of hyperparameters, since it does not have to follow the rigid grid pattern of testing hyperparameters.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1C2bh--ETFTMS9d3TPl2c_WlmFtQPviUv\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìö **Digging deeper** : In the paper [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/v13/bergstra12a.html) by Bergstra and Bengio, the authors show empirically and theoretically that random search is more efficient for parameter optimization than grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
