{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# I. Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Decisions trees, although really interesting models, are quite limited. \n",
    "\n",
    "Most of the time, they will be outperformed by logistic regression and SVM models.\n",
    "\n",
    "But decision trees can be used together to bring a better result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Imagine assigning a set of complex tasks to a group of people: most of the times, the average (or consensus) result will outperform the results of any single person in the group. This is sometimes referred as collective intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An intuitive way of seeing that is the following experiment:\n",
    "\n",
    "- Imagine a bot that randomly answers any question right 51 % of the time\n",
    "\n",
    "Pretty inefficient..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "but if we ask that bot the same question:\n",
    "- 1000 times, you will have a majority of right answers about 75 % of the time\n",
    "- 10000 times, you will have a majority of right answers about 97 % of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Thanks to the law of large numbers, having a large number of *not so accurate* models can create a powerful model\n",
    "\n",
    "But the models have to be as independant as possible to be true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This method can be applied to machine learning models: this is called **ensemble learning**.\n",
    "\n",
    "Still, some details have to be discussed:\n",
    "- How to use the vote of each individual (i.e. model) in our ensemble?\n",
    "- How to ensure the independance of each individual in our ensemble?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.1. Voting system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first thing to define is the voting system in our ensemble.\n",
    "\n",
    "Imagine we have an ensemble of 3 binary classification models, predicting the following results:\n",
    "\n",
    "| | Predicted class | Probability |\n",
    "|:--:|:--:|:--:|\n",
    "| model 1 | 0 | 0.05 |\n",
    "| model 2 | 1 | 0.6 |\n",
    "| model 3 | 1 | 0.55 |\n",
    "\n",
    "Where:\n",
    "- the probability is the result of `.predict_proba()`\n",
    "- the predicted class is `1` if the probability > 0.5, `0` otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There could be many ways to define such a system, but we will talk about two:\n",
    "- majoritary vote \n",
    "- soft vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Majoritary vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the majority vote: the class that has the majority of votes is the final prediction.\n",
    "\n",
    "In our exemple, two models out of three predict class 1, then our ensemble will predict class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Soft vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Soft vote takes into account the weights of each individual: instead of taking the majority vote, it averages the probabilities, and makes a prediction based on it.\n",
    "\n",
    "In our example, the average probability would be:\n",
    "\n",
    "$$\n",
    "\\text{average proba} = \\frac{0.05 + 0.6 + 0.55}{3} = 0.4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then we would apply the same threshold as for any prediction:\n",
    "- if average probability > 0.5: predict class 1\n",
    "- otherwise predict class 0\n",
    "\n",
    "Thus in our case it would predict class 0 with this vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Soft vote outperforms majoritary vote most of the time, because it takes into account the confidence of the model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# I.2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bagging is contraction of **bootstrap** and **aggregating**.\n",
    "\n",
    "This is a way of having independant individuals in our ensemble: it allows to have independant models and thus a more powerful ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bootstrap is just random sampling with replacement.\n",
    "\n",
    "Is other words, we will just randomly select samples in our dataset, *with replacement*. \n",
    "\n",
    "With replacement meaning we may draw several times the same sample from the original dataset.\n",
    "\n",
    "So for example, from an original dataset, we may end up with three, slightly different, subsamples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/bootstrap.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For an ensemble method, on each of those subsamples, we will train a model.\n",
    "\n",
    "The results of those models will then be aggregated (throught majoritary or soft vote)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/bagging.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# II. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A random forest is just a bagging of decision trees.\n",
    "\n",
    "Although this might sounds simple, this is one of the most powerful machine learning models at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The implementation in scikit-learn, for a classification random forest, is the following:\n",
    "```python\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can easily understand most of the hyperparameters:\n",
    "- `n_estimators` is the number of decision trees to grow\n",
    "- `criterion` is either `gini` or `entropy`\n",
    "- `max_depth` is the maximum depth of the trees\n",
    "\n",
    "And there are some new ones that you might guess:\n",
    "- `bootstrap`\n",
    "- `max_samples`\n",
    "- `max_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.1. Bootstrapping of samples, boostrapping of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Up to now, we only spoke about **samples bootstrapping**: we performed random sampling (with replacement) on the samples.\n",
    "\n",
    "This way, we ended up with **subsamples**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is exactly what allows the hyperparameters `bootstrap` and `max_samples`. By default, the values are:\n",
    "- `bootstrap=True` meaning there is bootstrapping on the samples\n",
    "- `max_samples=None` meaning our subsamples will have as much samples as the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But one can also perform **features bootstrapping**: we only select, with replacement, a subset of features for each tree.\n",
    "\n",
    "We then speak about **subspaces** of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Scikit-learn allows to do such thing, thanks to the hyperparameter `max_features`:\n",
    "- if `max_features='auto'`: each subspace will have `sqrt(n_features)`\n",
    "- if `max_features=3` for example: each subspace will have 3 features\n",
    "\n",
    "The default value is `'auto'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.2. Out of bag evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thanks to samples bootstrapping, any tree is trained on a subsample only of the training dataset.\n",
    "\n",
    "Then samples that are left out are called **out of bag** samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the decision tree never saw them during training, one can evaluate the tree on those samples: this is called **out of bag evaluation**.\n",
    "\n",
    "This is implemented in scikit-learn, and can be activated with the hyperparameter `oob_score=True`. Then the score can be retrieved with the attribute `.oob_score_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.3. More randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to ensure that all the trees in a random forest are as much independant as possible, one more randomness is added.\n",
    "\n",
    "Instead of choosing the best feature to split a node (as in a classical decision tree), the algorithm will choose the best feature to split **among a random set of available features**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because of that, some trees might not find the optimal split. \n",
    "\n",
    "But thanks to that, the trees are more independant, then the forest might be more robust, and less likely to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To summarize, there are 3 levels of randomness in a random forest:\n",
    "- In the bagging of the samples\n",
    "- In the bagging ot the features\n",
    "- In the feature selection in the split of a node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## III. Implementation example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's have an example of use on a toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As usual, we just have to:\n",
    "- instantiate the model\n",
    "- train the model on the train dataset\n",
    "- evaluate the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T09:21:57.971454Z",
     "start_time": "2019-10-21T09:21:57.928358Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "print('accuracy:', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Finally, we can have a look at the **importance of our features** for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T09:22:04.571465Z",
     "start_time": "2019-10-21T09:22:04.564070Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Features importance')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(load_iris().feature_names, rf.feature_importances_)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Features importance')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
